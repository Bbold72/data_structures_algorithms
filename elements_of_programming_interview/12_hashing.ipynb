{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing  \n",
    "A hash table is a data structure used to store keys, optionally, with corresponding values. Inserts, deletes, and lookups run in $O(1)$ time on average.    \n",
    "   \n",
    "The underlying idea is to store keys in an array. A key is stored in the array locations (\"slots\") based on its \"hash code\". The hash code is an integer computed from the key by a hash function. If the hash function is chosen well, the objects are distributed uniformly across array locations.    \n",
    "   \n",
    "If two keys map to the same location, a \"collision\" has occurred. the standard mechansim to deal with collisions is to maintain a linked list of objects at each array location. If the hash function does a good job of spreading objects across the underlying array and takes $O(1)$ time to compute, on average, lokkups, insertions, and deletions have $O(1 + n/m)$ time complexity, where $n$ is the number of objects and $m$ is the length of the array.   \n",
    "   \n",
    "If the \"load\" $n/m$ grows large, rehashing can be applied, but is expensive $O(n + m)$    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict, namedtuple, OrderedDict\n",
    "import functools\n",
    "from typing import DefaultDict, Dict, List, Set\n",
    "\n",
    "from utils import run_tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips\n",
    "- Hash tables have the **best theoretical and real-world performance** for lookup, insert and delete. Each of these operations has $O(1)$ time complexity. The $O(1)$ time complexity for insertions is for the average case - a single insert can take $O(n)$ if the hash table has to be resized.  \n",
    "- Consider using a hash code as a **signature** to enhance performance, e.g., to filter out candidates.  \n",
    "- Consider using a precomputed lookup table instead of boilerplate if-then code for mappings, e.g., from character to value or character to character.\n",
    "- When defining your own type that will be put in a hash table, be sure you understand the relationship between **logical equality** and the fields the hash function must inspect. Specifically, anytime equality is implemented, it is imperative that the correct hash function is also implemented, o/w when objects are placed in hash tables, logically equivalent objects may appear in different buckets, leading to lookups returning false, even when the searched item is present.\n",
    "- Somtimes you'll need a **multimap**, i.e., a map that contains multiple values for a single key, or a bi-directional map. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Hash Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "def string_hash(s: str, modulus: int) -> int:\n",
    "    mult = 997\n",
    "    return functools.reduce(lambda v, c: (v * mult + ord(c)) & modulus, s, 0)\n",
    "\n",
    "print(string_hash('cat', 10))\n",
    "print(string_hash('cats', 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Anagrams\n",
    "An anagram is a word formed by rearranging the letters of another word   \n",
    "Give a set of words, return groups of anagrams of these words   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['debitcard', 'badcredit'], ['elvis', 'lives', 'levis'], ['silent', 'listen']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_anagrams(words: List[str]) -> List[List[str]]:\n",
    "    ''' \n",
    "    key idea is to map a strings to a representative\n",
    "    the representative can be the sorted version of the string since \n",
    "    anagrams will have the same sorted representation\n",
    "    '''\n",
    "    sorted_string_to_anagram: DefaultDict[str, List[str]] = defaultdict(list)\n",
    "\n",
    "    for w in words:\n",
    "        w_sorted = ''.join(sorted(w))       # sorted returns a character array\n",
    "        sorted_string_to_anagram[w_sorted].append(w)\n",
    "\n",
    "    return [\n",
    "        group for group in sorted_string_to_anagram.values() if len(group) >= 2\n",
    "    ]\n",
    "\n",
    "words = ['debitcard', 'elvis', 'silent', 'badcredit', 'lives', 'freedom', 'listen', 'levis', 'money']\n",
    "find_anagrams(words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$O(nm\\log m)$ time complexity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variant: \n",
    "Design and $O(nm)$ algorithm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing a Hashable Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContactList:\n",
    "    def __init__(self, names: List[str]):\n",
    "        self.names = names \n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        # conceptually we want to hash the set of names. \n",
    "        # since the set type is mutable, it cannot by hashable.\n",
    "        # therefore use a frozen set\n",
    "        return hash(frozenset(self.names))\n",
    "\n",
    "    def __eq__(self, other) -> bool:\n",
    "        return set(self.names) == set(other.names)\n",
    "\n",
    "\n",
    "def merge_contanct_lists(contacts: List[ContactList]) -> ContactList:\n",
    "    return list(set(contacts))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hash codes are often cached for performance, with the caveat that cache must be cleared if object fields that are referenced by the hash function are updated.   \n",
    "Could also cache equality function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1: Test for Palindromic Permutations\n",
    "Test whether letters in a word can be permuted to form a palindrome.   \n",
    "e.g., \"edified\" can be permuted to form \"deified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def is_string_permutable_to_palindrome(s: str) -> bool:\n",
    "    ''' \n",
    "    a palindrome has an even count of characters (because have to match pairs)\n",
    "    except can have on character with an odd count\n",
    "    '''\n",
    "    character_counts = Counter(s)\n",
    "    return sum(c % 2 for c in character_counts.values()) <= 1\n",
    "\n",
    "print(is_string_permutable_to_palindrome('edified'))\n",
    "print(is_string_permutable_to_palindrome('cat'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$O(n)$ time complexity and $O(c)$ space complexity where $c$ is the unique number of characters in the string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2: Is an Anonymous List Constructable\n",
    "Given the text for an anonymous letter and the text of a magazine, check if the letter could be constructed from the magazine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_letter_constructible_from_magazine(letter: str, magazine: str) -> bool:\n",
    "\n",
    "    # compute frequencies for characters in letter\n",
    "    char_letter_freq = Counter(letter)\n",
    "\n",
    "    for c in magazine:\n",
    "        if c in char_letter_freq:\n",
    "            char_letter_freq[c] -= 1\n",
    "            if char_letter_freq[c] == 0:\n",
    "                del char_letter_freq[c]\n",
    "                if not char_letter_freq:\n",
    "                    # all characters in letter matched\n",
    "                    return True\n",
    "                    \n",
    "    # empty dict means every character in letter can\n",
    "    # be matched to a character in magazine\n",
    "    return not char_letter_freq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3: Implement an ISBN Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LruCache:\n",
    "    def __init__(self, capacity: int) -> None:\n",
    "        self._capacity = capacity\n",
    "        self._isbn_price_table: OrderedDict[int, int] = OrderedDict() \n",
    "\n",
    "    def lookup(self, isbn: int) -> int:\n",
    "        if isbn not in self._isbn_price_table:\n",
    "            return -1\n",
    "        \n",
    "        # since just returned price, move isbn to front\n",
    "        price = self._isbn_price_table.pop(isbn)\n",
    "        self._isbn_price_table[isbn] = price\n",
    "        return price\n",
    "\n",
    "    def insert(self, isbn: int, price: int) -> None:\n",
    "        if isbn in self._isbn_price_table:\n",
    "            price = self._isbn_price_table.pop(isbn)\n",
    "        elif len(self._isbn_price_table) == self._capacity:\n",
    "            self._isbn_price_table.popitem(last=False)\n",
    "        self._isbn_price_table[isbn] = price \n",
    "    \n",
    "    def erase(self, isbn: int) -> bool:\n",
    "        return self._isbn_price_table.pop(isbn, None) is not None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$O(1)$ time complexity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.4: Compute the LCA, Optimizing for Close Ancestors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.5: Find the Nearest Repeated Entry in an Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "-1\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "def nearest_repeated_entries(paragraph: str) -> int:\n",
    "    paragraph = paragraph.lower().split(' ')\n",
    "\n",
    "    word_to_latest_index: Dict[str, int] = {}\n",
    "    nearest_repeated_distance = float('inf')\n",
    "\n",
    "    for i, word in enumerate(paragraph):\n",
    "        if word in word_to_latest_index:\n",
    "            nearest_repeated_distance = min([nearest_repeated_distance, i - word_to_latest_index[word]])\n",
    "        word_to_latest_index[word] = i\n",
    "    \n",
    "    return int(nearest_repeated_distance) if nearest_repeated_distance != float('inf') else -1\n",
    "\n",
    "paragraph = 'All work and no play makes for no work no fun and no results'\n",
    "print(nearest_repeated_entries(paragraph))\n",
    "paragraph = 'cat in the hat'\n",
    "print(nearest_repeated_entries(paragraph))\n",
    "paragraph = 'cat in the hat is still a cat'\n",
    "print(nearest_repeated_entries(paragraph))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.6: Find the Smallest Subarray Covering All Values\n",
    "In a list of strings, find the interval that covers all strings in a sub array  \n",
    "e.g. ['apple', 'banana', 'apple', 'apple', 'dog', 'cat', 'apple', 'dog', 'banana', 'apple', 'cat', 'dog'], ['banana', 'cat'] -> (8, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Interval(start=8, end=10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Interval = namedtuple('Interval', ('start', 'end'))\n",
    "\n",
    "def find_smallest_subarray_covering_set(paragraph: List[str], keywords: Set[str]) -> Interval:\n",
    "    ''' \n",
    "    advance right pointer until cover set, then advance left pointer to see if smaller set\n",
    "    '''\n",
    "    keywords_to_cover = Counter(keywords)\n",
    "    result = Interval(-1, -1)\n",
    "    remaining_to_cover = len(keywords)\n",
    "    left = 0\n",
    "\n",
    "    for right, word in enumerate(paragraph):\n",
    "        if word in keywords:\n",
    "            keywords_to_cover[word] -= 1\n",
    "            if keywords_to_cover[word] >= 0:      # if this count is negative, implies keyword showed up multple time in subarray\n",
    "                remaining_to_cover -= 1\n",
    "\n",
    "        # advance left until key_words_to_cover \n",
    "        # does not contain all keywords\n",
    "        while remaining_to_cover == 0:\n",
    "            if result == Interval(-1, -1) or right - left < result.end - result.start:\n",
    "                result = Interval(start=left, end=right)\n",
    "            word_left = paragraph[left]\n",
    "            if word_left in keywords:\n",
    "                keywords_to_cover[word_left] += 1\n",
    "                if keywords_to_cover[word_left] >= 0:\n",
    "                    remaining_to_cover += 1\n",
    "            left += 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "find_smallest_subarray_covering_set(['apple', 'banana', 'apple', 'apple', 'dog', 'cat', 'apple', 'dog', 'banana', 'apple', 'cat', 'dog'], ['banana', 'cat'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time complexity is $O(n)$, where $n$ is the length of the array, since for each of the two indices we spend $O(1)$ time per advance, and each is advanced at most $n-1$ times"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variant 12.6.A:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variant 12.6.B:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variant 12.6.C:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.7: Find the Smallest Subarray Sequentially Covering All Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing each entry of the paragraph array entails a constant number of lookups and updates, leading to an $O(n)$ time complexity, where $n$ is the length of the paragraph array. The additional space complexity is dominated by the three hash tables, i.e., $O(m)$, where $m$ is the number of keywords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.8: Find the Longest Subarray with Distinct Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_distinct_subarray(elements: List[str]) -> int:\n",
    "    element_to_last_occurrence: Dict[str, int] = {}\n",
    "    max_subarray_len = float('-inf')\n",
    "    start = 0\n",
    "\n",
    "    for i, s in enumerate(elements):\n",
    "        if s not in element_to_last_occurrence:\n",
    "            element_to_last_occurrence[s] = i \n",
    "        else:\n",
    "            max_subarray_len = max(max_subarray_len, i - start)\n",
    "            start = element_to_last_occurrence[s] + 1\n",
    "            element_to_last_occurrence[s] = i \n",
    "    \n",
    "    # check endpoint\n",
    "    max_subarray_len = max(max_subarray_len, i - start + 1)\n",
    "\n",
    "    return -1 if max_subarray_len == float('-inf') else int(max_subarray_len)\n",
    "\n",
    "\n",
    "inputs = (['f', 's', 'f', 'e', 't', 'w', 'e', 'n', 'w', 'e'], ['f', 's', 'f', 'e', 't', 'w', 'x', 'n', 'w', 'e'], ['f', 'f'], ['f', 's'], ['a', 'b', 'c', 'd'])\n",
    "outputs = [5, 7, 1, 2, 4]\n",
    "run_tests(longest_distinct_subarray, inputs, outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$O(n)$ time complexity since performed a constant number of operations per element"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.9: Find the Length of a Longest Contained Interval\n",
    "Write a program which takes as input a set of integers represented by an array, and returns the size of a large subset of integers in the array having the property that if two integers are in the subset, then so are all integers between them.   \n",
    "e.g.: [3, -2, 7, 9, 8, 1, 2, 0, -1, 5, 8] -> [-2, -1, 0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_contained_interval(A: List[int]) -> int:\n",
    "\n",
    "    unprocessed_entries = set(A)\n",
    "    max_interval_len = 0\n",
    "\n",
    "    while unprocessed_entries:\n",
    "        a = unprocessed_entries.pop()\n",
    "\n",
    "        # find the lower bound of the largest range containing a\n",
    "        lower_bound = a - 1\n",
    "        while lower_bound in unprocessed_entries:\n",
    "            unprocessed_entries.remove(lower_bound)\n",
    "            lower_bound -= 1\n",
    "\n",
    "        # find upper bound of the largest range containing a\n",
    "        upper_bound = a + 1\n",
    "        while upper_bound in unprocessed_entries:\n",
    "            unprocessed_entries.remove(upper_bound)\n",
    "            upper_bound += 1\n",
    "\n",
    "        max_interval_len = max([max_interval_len, upper_bound - lower_bound - 1])\n",
    "\n",
    "    return max_interval_len\n",
    "\n",
    "inputs = ([3, -2, 7, 9, 8, 1, 2, 0, -1, 5, 8], [3, -2, 7, 9, 8, 1, 2, 0, -1, 5, 8, 4], [1, 2, 3], [1, 3, 5, 10], [1, 8, 3, 9, 2, 7], [1, 8, 3, 9, 2, 7, 10], [1])\n",
    "outputs = [6, 8, 3, 1, 3, 4, 1]\n",
    "run_tests(longest_contained_interval, inputs, outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$O(n)$ time complexity, where $n$ is the array length, since add and remove array elements in the hash table no more than once"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.10: Compute All String Decompositions\n",
    "Take a string (sentence) and a list of substrings (words) and see if the concatenation of substrings is contained in the larger string. The list of substrings can contain duplicates. Each substring must appear once in the sentence and order does not matter. Return a list of integers corresponding to the start indexes of each occurrence\n",
    "e.g.: 'amanaplanacanal', ['can', 'apl', 'ana'] -> \"aplanacan\", 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_all_substrings(sentence: str, words: List[str]) -> List[int]:\n",
    "    def match_all_words_in_dict(start: int) -> bool:\n",
    "        curr_string_freq = Counter()\n",
    "        for i in range(start, start + len(words) * unit_size, unit_size):\n",
    "            curr_word = sentence[i:(i + unit_size)]\n",
    "            freq = word_to_freq[curr_word]\n",
    "            if freq == 0:     # if not in words \n",
    "                return False \n",
    "            curr_string_freq[curr_word] += 1\n",
    "            if curr_string_freq[curr_word] > freq:  # curr_word occurs to many times for a match to be possible\n",
    "                return False \n",
    "        return True\n",
    "\n",
    "    word_to_freq = Counter(words)\n",
    "    unit_size = len(words)\n",
    "    return [\n",
    "        i for i in range(len(sentence) - unit_size * len(words) + 1) if match_all_words_in_dict(i)\n",
    "    ]\n",
    "\n",
    "find_all_substrings('amanaplanacanal', ['can', 'apl', 'ana'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $m$ be the number of words and $n$ the length of each word. Let $N$ be the length of the sentence. For any fixed $i$, to check if the string of length $nm$ starting at an offset of $i$ in the sentence is the concatenation of all words has time complexity $O(nm)$, assuming a hash table is used to store the set of words. This implies the overall time complexity is $O(Nnm)$. In practice, the checks are likely much faster since stop as soon as a mismatch is detected."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1: Collatz Conjecture\n",
    "Take any natural number. If it is odd, triple it and add one. If it is even, halve it. Write a program to test the Collatz conjecture for first n integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_collatz_conjecture(n: int):\n",
    "    ''' \n",
    "    - Reuse compuations by storing all the numbers you have already proved to converge to 1\n",
    "    - To save time, skip even numbers\n",
    "    - If test every number up to k, can stop as soon as reached a number less than k. Don't need to save them in hash table either\n",
    "    '''\n",
    "    verified_numbers = set()\n",
    "\n",
    "    for i in range(3, n+1):   # dont need to check 1 and 2\n",
    "        sequence = set()\n",
    "        num = i\n",
    "\n",
    "        while num >= i:     # if num is less than i, already has been verified\n",
    "           \n",
    "\n",
    "             # check if in cycle\n",
    "            if num in sequence:\n",
    "                print(i)\n",
    "                return False \n",
    "            else:\n",
    "                sequence.add(num)\n",
    "\n",
    "           # update num     \n",
    "            if num % 2:     # odd\n",
    "                if i in verified_numbers:\n",
    "                    break \n",
    "                verified_numbers.add(i)\n",
    "                num = num * 3 + 1\n",
    "            else:\n",
    "                num /= 2\n",
    "            \n",
    "test_collatz_conjecture(100000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much can be said about time complexity other than it is proportional to $O(n)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.12: Implement a Hash Function for Chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('data-structures-algorithms')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "893eabf024544e5e4ccd37f92d923a15afaa2331429d096efe9b57dc3359fd4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
